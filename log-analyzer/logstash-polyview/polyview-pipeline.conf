input {
   file {
#      path => "d:\repositories\svn\polyview\branches\N7_2_2_0_0_1830_patch\nms\PolyView\logs\1.pvman-startup._log"
      path => "d:\repositories\svn\polyview\trunk\nms\PolyView\logs\pvman.log"
      start_position => "beginning"
      sincedb_path => "d:\repositories\git\web\log-analyzer\log-analyzer\logstash-polyview\_sincedb-logstash-polyview-dataset"
      ignore_older => 9999999999999999
      type => "polyview"
   }
}

filter {	
    # All lines that does not start with %{TIMESTAMP} or ' ' + %{TIMESTAMP} belong to the previous event
    multiline {
        pattern => "(([\s]+)20[0-9]{2}-)|20[0-9]{2}-"
        negate => true
        what => "previous"
    }
 
    # myApplication
    if [type] == "polyview" {
        grok {
            # patterns_dir => ["/etc/logstash/grok"]
            # \A%{TIMESTAMP_ISO8601} \[%{JAVACLASS}] \[%{PROG}] \[%{LOGLEVEL}] %{JAVALOGMESSAGE}
            match => [
                "message", "\A%{TIMESTAMP_ISO8601:date}%{SPACE}\[%{JAVACLASS:logger}]%{SPACE}\[%{PROG:thread}]%{SPACE}\[%{LOGLEVEL:loglevel}]%{SPACE}%{JAVALOGMESSAGE:logmessage}"
                ]
            add_tag => "polyview-log"
        }
        # Something wrong occurred !!! :O
        if "_grokparsefailure" in [tags] {
            grok {
                # patterns_dir => "/etc/logstash/grok"
                 match=>[
                    "message","(?<content>(.|\r|\n)*)"
                    ]
                 }
        }
    }
}

output {
#   stdout { codec => "json" }
   file { 
        codec => "json"
        path => "d:\repositories\git\web\log-analyzer\log-analyzer\logstash-polyview\pvman-1-copy.log"
   }
   elasticsearch { hosts => ["localhost:9200"] }
}
